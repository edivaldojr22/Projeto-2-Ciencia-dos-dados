{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome:Edivaldo Rangel\n",
    "\n",
    "Nome:Henrique Feola"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import numpy as np\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import string\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: @Estudan83556905"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "#with open('auth.pass') as fp:    \n",
    " #   data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "#auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "#auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'it 2'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "#api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "#i = 1\n",
    "#msgs = []\n",
    "#msgs_filtradas = []\n",
    "#for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    " #   msgs.append(msg.full_text.lower())\n",
    "  #  i += 1\n",
    "   # if i > 1200:\n",
    "    #    break\n",
    "        \n",
    "#msgs_filtradas = set(msgs)\n",
    "\n",
    "#Tweet = []\n",
    "#for tweet in msgs_filtradas:\n",
    " #   Tweet.append(tweet)\n",
    "  #  if len(Tweet) >= n:\n",
    "   #     break\n",
    "    \n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "\n",
    "#shuffle(Tweet)\n",
    "#print(len(Tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "#if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    " #   \n",
    "    #Abre o arquivo para escrita\n",
    "  #  writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "   # dft = pd.DataFrame({'Treinamento' : pd.Series(Tweet[:t])})\n",
    "    #dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "   # dfc = pd.DataFrame({'Teste' : pd.Series(Tweet[t:])})\n",
    "   # dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    #writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def limpa(texto):\n",
    "    pontuacao = '[!\\-.:?;]'\n",
    "    padrao = re.compile(pontuacao)\n",
    "    texto_limpo = re.sub(padrao, ' ', texto)\n",
    "    return texto_limpo\n",
    "def replace(coluna):\n",
    "    coluna = coluna.replace(\"https://\",\"\").replace(\".\",\" \").replace(\":\",\" \").replace(\",\",\" \").replace(\"'\",\" \")\\\n",
    "    .replace('\"', \" \").replace(\"#\",\"\").replace(\"-\",\"\").replace(\"•\", \"\").replace(\"\\n\\n\", \" \").replace(\"\\n\", \" \")\\\n",
    "    .replace(\"—\", \" \").replace(\"rt\", \"\").replace(\"?\", \" \").replace(\"!\", \" \").replace(\"/\",\"\").replace(\";\", \" \")\\\n",
    "    .replace(\"{\", \"\").replace(\"}\", \"\").replace(\"|\",\"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"_\", \"\")\\\n",
    "    .replace(\"__\", \"\").replace(\"\\\\\",\"\").replace(\"´\", \"\").replace(\"ˆ\",\"\").replace(\"˜\",\"\").replace(\"\\\\\", \" \\\\\").replace(\"U+\", \" U+\")\n",
    "    return coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_treino = pd.read_excel('it 2.xlsx', sheet_name = 'Treinamento')\n",
    "dados_teste = pd.read_excel('it 2.xlsx', sheet_name = 'Teste')\n",
    "dados_idx = dados_treino.set_index('Treinamento')\n",
    "dados_idx_teste = dados_teste.set_index('Classificacao')\n",
    "dados_relevante = dados_idx[dados_idx.Classe == 1]\n",
    "dados_irrelevante = dados_idx[dados_idx.Classe == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = str((dados_idx.index))\n",
    "tweets_teste = dados_idx_teste.values.tolist()\n",
    "tweets_re = str((dados_relevante.index))\n",
    "tweets_ir = str((dados_irrelevante.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpando os tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_limpo = limpa(tweets.lower())\n",
    "tweets_re_limpo = limpa(tweets_re.lower())\n",
    "tweets_ir_limpo = limpa(tweets_ir.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "universo_raw = pd.Series(tweets_limpo.split())\n",
    "relevantes_raw =  pd.Series(tweets_re_limpo.split())\n",
    "irrelevantes_raw =  pd.Series(tweets_ir_limpo.split())\n",
    "## retirando os \\n\n",
    "universo = replace(universo_raw)\n",
    "relevantes = replace(relevantes_raw)\n",
    "irrelevantes = replace(irrelevantes_raw) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_universo = universo.value_counts(True)\n",
    "tabela_relevante = relevantes.value_counts(True)\n",
    "tabela_irrelevante = irrelevantes.value_counts(True)\n",
    "tabela_relevante_abs = relevantes.value_counts()\n",
    "tabela_irrelevante_abs = irrelevantes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Probabilidade_relevantes = len(tabela_relevante)/len(tabela_universo)\n",
    "Probabilidade_irrelevantes = len(tabela_irrelevante)/len(tabela_universo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Documents\\Python Scripts\\python dowload\\lib\\site-packages\\pandas\\core\\series.py:951: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n"
     ]
    }
   ],
   "source": [
    "def classifica(tweet,a,b):\n",
    "    if a>b:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0 \n",
    "Lista_relevante_final = []\n",
    "Lista_irrelevante_final = []\n",
    "Classificacao = []\n",
    "for tweet in tweets_teste:\n",
    "    for frase in tweet:\n",
    "        lista_rele = []\n",
    "        lista_irrele = []\n",
    "        frase_limpa_raw = limpa(frase.lower())\n",
    "        frase_limpa = frase_limpa_raw.strip()\n",
    "        palavras = frase_limpa.split()\n",
    "         # Laplace\n",
    "        prob_relevante = (tabela_relevante_abs[palavras].fillna(0) + 1)/(len(set(universo)) + len(relevantes))\n",
    "        prob_irrelevante = (tabela_irrelevante_abs[palavras].fillna(0) +1)/(len(set(universo)) + len(irrelevantes))\n",
    "        lista_rele.append(prob_relevante)\n",
    "        lista_irrele.append(prob_irrelevante)\n",
    "        Lista_relevante_final.append(lista_rele)\n",
    "        Lista_irrelevante_final.append(lista_irrele)\n",
    "# Naive Bayes\n",
    "\n",
    "        for frase in Lista_relevante_final:\n",
    "            for palavra in frase:\n",
    "                Prob_rel = palavra.prod() *Probabilidade_relevantes   \n",
    "        for frase in Lista_irrelevante_final:\n",
    "            for palavra in frase:\n",
    "                Prob_irrel = palavra.prod() * Probabilidade_irrelevantes\n",
    "        Classific = classifica(tweet, Prob_rel,Prob_irrel) \n",
    "        Classificacao.append(Classific)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ZIP does not support timestamps before 1980",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-8a58c0fea16d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdados_teste\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Simulacao\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mClassificacao\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdados_teste\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"it_2_classificado.xlsx\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdados_teste\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\python dowload\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes)\u001b[0m\n\u001b[0;32m   2125\u001b[0m         formatter.write(excel_writer, sheet_name=sheet_name, startrow=startrow,\n\u001b[0;32m   2126\u001b[0m                         \u001b[0mstartcol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstartcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreeze_panes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfreeze_panes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2127\u001b[1;33m                         engine=engine)\n\u001b[0m\u001b[0;32m   2128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2129\u001b[0m     def to_json(self, path_or_buf=None, orient=None, date_format=None,\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\python dowload\\lib\\site-packages\\pandas\\io\\formats\\excel.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine)\u001b[0m\n\u001b[0;32m    662\u001b[0m                            freeze_panes=freeze_panes)\n\u001b[0;32m    663\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mneed_save\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 664\u001b[1;33m             \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Python Scripts\\python dowload\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1950\u001b[0m         \"\"\"\n\u001b[0;32m   1951\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1952\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1954\u001b[0m     def write_cells(self, cells, sheet_name=None, startrow=0, startcol=0,\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\python dowload\\lib\\site-packages\\xlsxwriter\\workbook.py\u001b[0m in \u001b[0;36mclose\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    302\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileclosed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileclosed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_store_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\python dowload\\lib\\site-packages\\xlsxwriter\\workbook.py\u001b[0m in \u001b[0;36m_store_workbook\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    674\u001b[0m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m                 \u001b[0mxlsx_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxml_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\python dowload\\lib\\zipfile.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, filename, arcname, compress_type, compresslevel)\u001b[0m\n\u001b[0;32m   1708\u001b[0m             )\n\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1710\u001b[1;33m         \u001b[0mzinfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZipInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marcname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1712\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mzinfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\python dowload\\lib\\zipfile.py\u001b[0m in \u001b[0;36mfrom_file\u001b[1;34m(cls, filename, arcname)\u001b[0m\n\u001b[0;32m    516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misdir\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[0marcname\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m         \u001b[0mzinfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marcname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m         \u001b[0mzinfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternal_attr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mst_mode\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;36m0xFFFF\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<<\u001b[0m \u001b[1;36m16\u001b[0m  \u001b[1;31m# Unix attributes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misdir\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\python dowload\\lib\\zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, date_time)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdate_time\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1980\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ZIP does not support timestamps before 1980'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[1;31m# Standard values:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: ZIP does not support timestamps before 1980"
     ]
    }
   ],
   "source": [
    "dados_teste[\"Simulacao\"] = Classificacao\n",
    "dados_teste.to_excel(\"it_2_classificado.xlsx\")\n",
    "dados_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = 0\n",
    "falso_pos = 0\n",
    "neg = 0\n",
    "falso_neg = 0\n",
    "total = len(dados_teste[\"Classificacao\"])\n",
    "\n",
    "for [e,i] in zip(dados_teste[\"Classificacao\"], dados_teste[\"Simulacao\"]):\n",
    "    if e == 1:\n",
    "        if i == 1:\n",
    "            pos += 1\n",
    "        else: \n",
    "            falso_neg += 1\n",
    "    if e == 0:            \n",
    "        if i == 0:\n",
    "            neg +=1\n",
    "        else:\n",
    "            falso_pos +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdadeiros relevantes:  22.0 %\n",
      "Falsos relevantes:  38.5 %\n",
      "Verdadeiros irrelevantes:  23.0 %\n",
      "Falsos irrelevantes:  16.5 %\n",
      "___________________________________\n",
      "Acertos:  45.0 %\n",
      "Erros:  55.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Verdadeiros relevantes: \", round((pos/total)*100,2), \"%\")\n",
    "print(\"Falsos relevantes: \", round((falso_pos/total)*100, 2), \"%\")\n",
    "print(\"Verdadeiros irrelevantes: \", round((neg/total)*100,2), \"%\")\n",
    "print(f\"Falsos irrelevantes: \", round((falso_neg/total)*100, 2), \"%\")\n",
    "print(\"_\"*35)\n",
    "\n",
    "print(\"Acertos: \", round(((pos/total)+(neg/total))*100,2), \"%\")\n",
    "print(\"Erros: \", round(((falso_pos/total)+(falso_neg/total))*100,2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Em conclusão do nosso projeto 2, foi posivel analisar que, mesmo que menos de metade dos dados tenham sido confirmados pelo data base, os comentarios analisados sobre este tipo de genero cinematico possui muito mais comentários irrelevantes para uma concentração e analise de dados, apontando que se alguem quiser ter uma boa base para retratar o feedback popular sobre o filme ou qualquer outro tipo de entretenimento, este tipo de rede social não é a melhor plataforma. Em suma, a rede social do twitter pode não ser o melhor lugar para fazer uma pesquisa detalhada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propondo diferentes cenarios para Naive Bayes\n",
    "\n",
    "#### Como o teorema de Bayes trata de probabilidades condicionais, em que, ambos os termos analisados são condicionalmente independentes, podemos supor que a analise de dados comutativos assim como na analise do projeto podem ser evidenciadas neste aspecto.\n",
    "#### Um exemplo de aplicação de Bayes fora dos procedimentos do projeto pode ser o exemplo de diagnósticos médicos, em que, dado a propabilidade do individuo ter certa doença ou prè-disposição a tal doença, a totalidade da pessoa efetivamente estar doente pode ser calculada com esta teorema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Não é recomendado utilizar o classificador para gerar novas amostras de treinamento\n",
    "\n",
    "#### Apesar de ser muito bom para fazer previsões em tempo real e necessitar de poucos dados para realizar uma classificação, ele não tem facilidade em relacionar fatores e seguir com padrões de comportamento, ou seja, ele pode não identificar certos padrões que seriam necessarios para a classificação efetiva dos termos analisados, principalmente na área de tweets gerados randomicamente e com emojis e caracteres especiais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
